{
    # the three mandatory tenant related properties
    "tenant": "mytenant",
    "channel": "apache_httpd",
    "vendor": "apache",

    # the default template to use for generating actual configuration files.
    # you can override this using the channelctl configure --profile examples/another_template
    # command line usage.     
    "channel_structure_profile": "input_kafka_processing",
    
    # where the data comes from. In this simple example only a host port is set.
    # the template will hard code the procotol used. Feel free to extend this template
    # with more information should you need to generate various sort of input protocols
    # (lumberjack, udp, ssl etc ..).
    "input": {
        "port": 9901,
        "host": "localhost"
    },

    # the processings you want to run on the data stream
    "processing": {
        "workers": 1,
        "executors": 1,
        "punchlets": [
            { "punchlet": "standard/common/input.punch" },
            { "punchlet": "standard/common/parsing_syslog_header.punch" },
            { "punchlet": "standard/apache_httpd/parsing.punch" },
            {
                "punchlet": "standard/apache_httpd/enrichment.punch",
                "punchlet_json_resources": ["standard/apache_httpd/http_codes.json"]
            },
            {
                "punchlet": "standard/apache_httpd/normalization.punch",
                "punchlet_json_resources": ["standard/apache_httpd/taxonomy.json"]
            },
            { "punchlet": "standard/common/geoip.punch" }
        ]
    },

    # where the resulting data goes
    "output" : {
        "elasticsearch": {
            "cluster": "es_search",
            "executors" : 1
        }
    },

    # some important runtime settings
    "runtime_settings" : {
        "childopts": "-server -Xms128m -Xmx128m"
    },

    # where the monitoring real time metrics should go
    "metrics": {
        "type": "elasticsearch",
        "settings": {
            "cluster" : "es_search"
        }
    }
}