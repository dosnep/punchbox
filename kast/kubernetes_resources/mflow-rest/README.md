#  MLFLOW Model REST API Deployment

##  Prerequisites
- a cluster up and running with kubernetes installed
-  kubectl configured to deploy resources in your cluster
- Docker image of your ML model

 
## Create DockerFile 
If you have use Punchplatform tools, you have generated a python PEX. 
Accordingly you can create a Docker image by using the example in ``mlflow-rest/create-docker-image``. 

Please follow these steps : 

 1. Put files generated by PEX in the folder ``resources``
 2. If you use specific python lib, please update the file ``requirements.txt``
 3. In directory where the Dockerfile is located  run the following command
```sh
sudo docker image build -t <your_image_registry>:tag  .
```
4. Push your image in your image registry with the command ```
sudo docker image push ```

## Configuration

You need to modify two field with your image registry informations :
- ``Deployment.spec.replicas.template.spec.imagePullSecrets[0].name``
- ``Deployment.spec.replicas.template.spec.containers[0].image``

In addition you can customize your deployment by modify (CPU, RAM, number of instances ...) in the file ``mlflow-model-rest.yaml``

 The REST API service is by default configured to run on a Kubernetes cluster on premise. 
If you have a kubernetes cluster in cloud you need to change the field ``Service.spec.type`` with the value ``LoadBalancer``


##  Deployment
First you need to create a docker registry secret :
```sh
kubectl create secret docker-registry regsecret \
--docker-server=<REGISTRY_FQDN> \
--docker-username=<USERNAME>\
--docker-password=<PASSWORD> \  
```

When you have created your secret you can expose your machine learning model by running this command  :
```sh
kubectl create -f kubernetes_resources/mlflow-rest/mlflow-model-rest.yaml
```
This file will create 2 kubernetes objects :
- a Service in charge to route request to ML models Pods, this service is type of NodePort or LoadBalancer(Cloud) to permit receive request from external services.
- a Deployment in charge of managing and scaling  a set of Pods

MLFlow Rest API will be exposed on port 31000 of yours Kubernetes nodes so you need to check your firewall configuration.

When you have check your firewall configuration you can send request to **ML model** with the url  ``{NodeIP}:31000``


##  Test
You can try your REST API by sending a POST request with curl.
```
curl -d '{"columns":["zero", "first", "second", "third", "fourth"], "data":[[0, 1, 2, 3, 4]]}' \
-H 'Content-Type: application/json; format=pandas-split' \
-X POST {NodeIP}:31000/invocations
```


## Scaling the Cluster
You can scale your  ML model   manually  by updating the number of `Deployment.spec.replicas` field. You can perform this with the `kubectl scale` command.
```sh
kubectl scale deploy mlflow-rest --replicas=2
```

